# -*- coding: utf-8 -*-
"""EGC Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PnpEasUDK6biycvuAFtEJdfq0Ra3C-Im
"""

import warnings
warnings.filterwarnings('ignore')
import os
import json

# Core Data Science Libraries
import numpy as np
import pandas as pd

# Visualization Libraries
import matplotlib.pyplot as plt
import seaborn as sns

# Deep Learning Framework
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, callbacks, regularizers

# Scikit-learn for Preprocessing & Metrics
from sklearn.model_selection import train_test_split
from sklearn.utils import class_weight
from sklearn.metrics import (
    confusion_matrix,
    classification_report,
    roc_curve,
    auc,
    f1_score
)

# Display settings
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
plt.style.use('seaborn-v0_8-whitegrid')

print("ECG HEARTBEAT CLASSIFICATION - COMPETITION NOTEBOOK")
print("HARDWARE CONFIGURATION")

# Check GPU availability
gpus = tf.config.list_physical_devices('GPU')

from google.colab import drive
drive.mount('/content/drive')

# Load training data
train_df = pd.read_csv("/content/drive/MyDrive/ECG dataset/mitbih_train.csv", header=None)
print(f"Loaded: {train_df.shape[0]:,} samples, {train_df.shape[1]} columns")

# Load test data
test_df = pd.read_csv("/content/drive/MyDrive/ECG dataset/mitbih_test.csv", header=None)
print(f"Loaded: {test_df.shape[0]:,} samples, {test_df.shape[1]} columns")

# Summary
print(f"Total samples: {train_df.shape[0] + test_df.shape[0]:,}")
print(f"Features per sample: {train_df.shape[1] - 1}")

np.random.seed(42)
tf.random.set_seed(42)

print("DATA EXPLORATION")

# Display sample data
print("\n Training Data Sample (first 5 rows, selected columns):")
print(train_df.iloc[:5, [0, 1, 2, 3, 4, 5, -1]].to_string())

print("\n Feature Statistics:")
print(train_df.iloc[:, :5].describe().round(4).to_string())

# Missing values check
missing = train_df.isnull().sum().sum() + test_df.isnull().sum().sum()
print(f"\n Missing Values: {missing} ({' None' if missing == 0 else 'Found'})")

# Data types
print(f"Data Type: {train_df.iloc[:, 0].dtype}")

X_train = train_df.iloc[:, :-1].values
y_train = train_df.iloc[:, -1].values.astype(int)
X_test = test_df.iloc[:, :-1].values
y_test = test_df.iloc[:, -1].values.astype(int)

class_names = {0: 'Normal', 1: 'Supraventricular', 2: 'Ventricular', 3: 'Fusion', 4: 'Unknown'}
num_classes = len(class_names)

unique, counts = np.unique(y_train, return_counts=True)
print("Training distribution:")
for cls, count in zip(unique, counts):
    print(f"  {class_names[cls]}: {count} ({count/len(y_train)*100:.1f}%)")

fig, axes = plt.subplots(1, 2, figsize=(12, 4))
axes[0].bar([class_names[c] for c in unique], counts, color='steelblue')
axes[0].set_title('Training Set Distribution')
axes[0].tick_params(axis='x', rotation=45)

unique_test, counts_test = np.unique(y_test, return_counts=True)
axes[1].bar([class_names[c] for c in unique_test], counts_test, color='coral')
axes[1].set_title('Test Set Distribution')
axes[1].tick_params(axis='x', rotation=45)
plt.tight_layout()
plt.show()

fig, axes = plt.subplots(5, 1, figsize=(10, 8))
for i, cls in enumerate(unique):
    sample_idx = np.where(y_train == cls)[0][0]
    axes[i].plot(X_train[sample_idx], linewidth=0.7, color='navy')
    axes[i].set_title(f'{class_names[cls]}', fontsize=9)
    axes[i].set_ylabel('Amp')
    axes[i].grid(True, alpha=0.3)
axes[-1].set_xlabel('Time Steps')
plt.tight_layout()
plt.show()

X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

y_train_encoded = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)
y_test_encoded = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)

print(f"X_train_reshaped shape: {X_train_reshaped.shape}")
print(f"X_test_reshaped shape: {X_test_reshaped.shape}")
print(f"y_train_encoded shape: {y_train_encoded.shape}")
print(f"y_test_encoded shape: {y_test_encoded.shape}")

from sklearn.model_selection import train_test_split

X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
    X_train_reshaped, y_train_encoded, test_size=0.2, random_state=42
)

print(f"X_train_split shape: {X_train_split.shape}")
print(f"y_train_split shape: {y_train_split.shape}")
print(f"X_val_split shape: {X_val_split.shape}")
print(f"y_val_split shape: {y_val_split.shape}")

model = models.Sequential([
    layers.Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=X_train_split.shape[1:]),
    layers.MaxPooling1D(pool_size=2),
    layers.Conv1D(filters=128, kernel_size=5, activation='relu'),
    layers.MaxPooling1D(pool_size=2),
    layers.Dropout(0.3),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(num_classes, activation='softmax')
])

model.summary()

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Callbacks
early_stopping = callbacks.EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

reduce_lr = callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    min_lr=1e-6
)

# Train the model
history = model.fit(
    X_train_split,
    y_train_split,
    epochs=50,
    batch_size=32,
    validation_data=(X_val_split, y_val_split),
    callbacks=[early_stopping, reduce_lr]
)

print("Model compilation and training complete.")

y_pred_proba = model.predict(X_test_reshaped)
print(f"Shape of y_pred_proba: {y_pred_proba.shape}")
print(f"First 5 predictions (probabilities):\n{y_pred_proba[:5].round(3)}")

y_pred = np.argmax(y_pred_proba, axis=1)
y_true = np.argmax(y_test_encoded, axis=1)

print(f"Shape of y_pred: {y_pred.shape}")
print(f"First 5 predicted labels: {y_pred[:5]}")
print(f"Shape of y_true: {y_true.shape}")
print(f"First 5 true labels: {y_true[:5]}")

accuracy = np.mean(y_pred == y_true)
print(f"Test Accuracy: {accuracy:.4f}")

print(classification_report(y_true, y_pred, target_names=[class_names[i] for i in sorted(class_names.keys())]))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[class_names[i] for i in sorted(class_names.keys())], yticklabels=[class_names[i] for i in sorted(class_names.keys())])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()
